-- TODO: df  = df.filter((df.Time - currTime)/60000 < 2)
-- TODO: use UDaF instead of extra streams
-- TODO: use table or stream???

create table NUM_DISTINCT_LOCATIONS3 WITH (PARTITIONS = 1) as
  select user_id, count(cast(latitude as string) + ' | ' + cast(longitude as string)) as num_locations
  from REALTIMESTREAM
  group by user_id
;

create table AVG_HEART_RATE3 WITH (PARTITIONS = 1) as
  select r.user_id, sum(r.heart_rate)/count(r.heart_rate) as avg_heart_rate
  from REALTIMESTREAM r
  group by r.user_id
;

create stream USER_WITH_NUM_DISTINCT_LOCATIONS1 WITH (PARTITIONS = 1) as
  select r.user_id as user_id, n.num_locations as num_locations
  from REALTIMESTREAM r
  join NUM_DISTINCT_LOCATIONS3 n on r.user_id = n.user_id
;

create stream USER_WITH_NUM_DISTINCT_LOCATIONS_AND_AVG_HEART_RATE WITH (PARTITIONS = 1) as
  select u.user_id as user_id, u.num_locations as num_locations, a.avg_heart_rate as avg_heart_rate
  from USER_WITH_NUM_DISTINCT_LOCATIONS1 u
  join AVG_HEART_RATE3 a on u.user_id = a.user_id
;

select u.user_id, u.AVG_HEART_RATE, u.NUM_LOCATIONS
from USER_WITH_NUM_DISTINCT_LOCATIONS_AND_AVG_HEART_RATE u
join HISTORICALTABLE h on u.user_id = h.user_id
window tumbling (size 10 seconds)
where u.avg_heart_rate < 50 or u.avg_heart_rate > 70
;

PEM_PATH=~/.ssh/mark-chen-IAM-key-pair.pem

# Control versions of resources (topics, streams, tables, connectors) to avoid namespace conflict between each consecutive run of experiments
RESOURCE_NAME_VERSION_ID=3

# Experiment parameters
NUM_PARTITIONS=30
NUM_PRODUCERS_PROCESSES_PER_MACHINE=2
PRODUCER_BATCH_SIZE=400
REPLACATING_FACTOR=1
WINDOW_TUMBLING_SECONDS=10

# if MODE=dev, then datagen connector will be used for real time data. Otherwise, you should manually run producer.py for real time data
MODE=prod

# if MODE=prod, PRODUCER_LIST must be set
PRODUCER_LIST=ec2-52-20-246-232.compute-1.amazonaws.com,ec2-174-129-46-139.compute-1.amazonaws.com,ec2-35-170-181-139.compute-1.amazonaws.com

# this variable is used to run `python3 operations sync` in order to sync files from your local to all remote machines. If you are hosting a website for this app, use brokers,ksqls,website. Otherwise if you just want to use localhost to run the UI, use brokers,ksqls
CLUSTERS=brokers,ksqls,website

# Overriding configs for topic creation. Note that docker-compose.yml contains different settings serving for default purpose.
KAFKA_LOG_DELETE_RETENTION_MS=60000
KAFKA_LOG_RENTENTION_BYTES=4294967296
KAFKA_LOG_RETENTION_MINUTES=5

# Other configs
DIR_DATA=/home/ubuntu/heart_watch/data/
DIR_DATA_MOUNT=/data/
DIR_SCHEMAS=/home/ubuntu/heart_watch/schemas/
DIR_SCHEMAS_MOUNT=/schemas/
FILE_DATA_HISTORICAL=historical_20000.data
FILE_DATA_REALTIME=realtime_100000.data
FILE_SCHEMA_REALTIME=realtime_value.avsc
FILE_SCHEMA_HISTORICAL=historical.avsc

HISTORICAL_POLL_INTERVAL=3600000
HISTORICAL_KEYFIELD=user_id
HISTORICAL_QUERY='select user_id, min_heart_rate, max_heart_rate from historical'

REALTIME_KEYFIELD=user_id
REALTIME_POLL_INTERVAL=100
REALTIME_ITERATIONS=1000000
REALTIME_OFFSET_RESET=earliest

LOGGER_NAME=HW
LOGGING_LEVEL=DEBUG
RSYNC_LOG_PATH=/Users/a67/rsync.log

GENERATED_AT_FIELD=generated_at
PROCESSING_AT_FIELD=processing_at
